{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Asymmetry Detection Models\n",
    "This notebook shows the process of load and train of a LSTM neuronal network to classify the asymmetry laterality of a PD patient or a control. In this notebook\n",
    "we will show different implementations of LSTMs (Normal and bidirectional) and with different hyperparameters."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5706cf0051e2286"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Requiered Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8365e2dd60c7786f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Roaming\\Python\\Python310\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "\n",
    "from src.model.asa_models import build_basic_lstm\n",
    "\n",
    "from src.settings import ROOT_DIR\n",
    "from src.utils.data_split import get_features_target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T04:51:25.119907Z",
     "start_time": "2024-03-25T04:51:03.666468Z"
    }
   },
   "id": "9cd6ca22b813d6a9",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data load"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d67e5a0ed8b1dc29"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_path = ROOT_DIR / 'data' / 'processed' / 'asa' / 'train.pkl'\n",
    "val_data_path = ROOT_DIR / 'data' / 'processed' / 'asa' / 'val.pkl'\n",
    "\n",
    "with open(train_data_path, 'rb') as file:\n",
    "    train_data = pickle.load(file)\n",
    "\n",
    "with open(val_data_path, 'rb') as file:\n",
    "    val_data = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T04:51:29.276618Z",
     "start_time": "2024-03-25T04:51:29.053635Z"
    }
   },
   "id": "470d5117ad154fc",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "124"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T04:51:32.355161Z",
     "start_time": "2024-03-25T04:51:32.331371Z"
    }
   },
   "id": "17e5d4a6442ac659",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, y_train = get_features_target(train_data)\n",
    "X_val, y_val = get_features_target(val_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T04:51:33.948428Z",
     "start_time": "2024-03-25T04:51:33.932782Z"
    }
   },
   "id": "9838be2466594916",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model\n",
    "### Simple LSTM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9254968e65943049"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 24"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T04:52:43.937116Z",
     "start_time": "2024-03-25T04:52:43.916797Z"
    }
   },
   "id": "62f554dd911c0143",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lstm = build_basic_lstm(128)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f61dfb7b877edf0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lstm.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-25T04:13:26.230200Z"
    }
   },
   "id": "eca913efd0be8140",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "checkpoint_filepath = str(ROOT_DIR) + '/results/asa/tmp/ckpt/checkpoint.model.keras'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d81fad342d81b66",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ../results/asa/lightning_logs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-25T04:13:26.236621Z"
    }
   },
   "id": "3a97d3a2d2703113",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "log_dir  =  str(ROOT_DIR) + '/results/asa/lightning_logs' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir , histogram_freq=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2be47c783eae24b2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.asarray(X_train, dtype=object).shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "337dd0d21d5b9ad3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lstm.fit(x=np.asarray(X_train, dtype=object), \n",
    "         y=np.asarray(y_train).astype(np.float32), \n",
    "         batch_size=BATCH_SIZE, \n",
    "         epochs=EPOCHS,\n",
    "         validation_data=(X_val, y_val),\n",
    "         callbacks=[tensorboard_callback, model_checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-25T04:13:26.246660Z"
    }
   },
   "id": "469783203358d0d6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "61dfa8c3b8a813b4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_9244\\3796037062.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array([df.values for df, _ in data])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 28\u001B[0m\n\u001B[0;32m     23\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     24\u001B[0m               optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     25\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 28\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[1;34m(value, ctx, dtype)\u001B[0m\n\u001B[0;32m    101\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[0;32m    102\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m--> 103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "#Code Snippet GPT\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a list 'data' containing tuples of (DataFrame, label)\n",
    "# where each DataFrame represents the time series data for a patient\n",
    "# and 'label' is the corresponding classification (1 or 0)\n",
    "\n",
    "data = train_data\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "X = np.array([df.values for df, _ in data])\n",
    "y = np.array([label for _, label in data])\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(None, 24)),  # None for variable sequence length\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T04:54:14.710820Z",
     "start_time": "2024-03-25T04:54:14.121256Z"
    }
   },
   "id": "acc8db4b4922559d",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "2/2 [==============================] - 318s 68s/step - loss: 0.6941 - accuracy: 0.6613\n",
      "Epoch 2/24\n",
      "2/2 [==============================] - 216s 73s/step - loss: 0.6895 - accuracy: 0.6613\n",
      "Epoch 3/24\n",
      "2/2 [==============================] - 213s 76s/step - loss: 0.6858 - accuracy: 0.6613\n",
      "Epoch 4/24\n",
      "2/2 [==============================] - 226s 91s/step - loss: 0.6795 - accuracy: 0.6613\n",
      "Epoch 5/24\n",
      "2/2 [==============================] - 175s 49s/step - loss: 0.6722 - accuracy: 0.6613\n",
      "Epoch 6/24\n",
      "2/2 [==============================] - 210s 83s/step - loss: 0.6657 - accuracy: 0.6613\n",
      "Epoch 7/24\n",
      "2/2 [==============================] - 221s 91s/step - loss: 0.6496 - accuracy: 0.6613\n",
      "Epoch 8/24\n",
      "2/2 [==============================] - 216s 89s/step - loss: 0.6393 - accuracy: 0.6613\n",
      "Epoch 9/24\n",
      "2/2 [==============================] - 225s 90s/step - loss: 0.6495 - accuracy: 0.6613\n",
      "Epoch 10/24\n",
      "2/2 [==============================] - 219s 95s/step - loss: 0.6355 - accuracy: 0.6694\n",
      "Epoch 11/24\n",
      "2/2 [==============================] - 215s 90s/step - loss: 0.6369 - accuracy: 0.6694\n",
      "Epoch 12/24\n",
      "2/2 [==============================] - 226s 102s/step - loss: 0.6388 - accuracy: 0.6694\n",
      "Epoch 13/24\n",
      "2/2 [==============================] - 172s 46s/step - loss: 0.6395 - accuracy: 0.6694\n",
      "Epoch 14/24\n",
      "2/2 [==============================] - 244s 37s/step - loss: 0.6392 - accuracy: 0.6694\n",
      "Epoch 15/24\n",
      "2/2 [==============================] - 137s 34s/step - loss: 0.6382 - accuracy: 0.6694\n",
      "Epoch 16/24\n",
      "2/2 [==============================] - 170s 35s/step - loss: 0.6372 - accuracy: 0.6694\n",
      "Epoch 17/24\n",
      "2/2 [==============================] - 148s 32s/step - loss: 0.6372 - accuracy: 0.6694\n",
      "Epoch 18/24\n",
      "2/2 [==============================] - 104s 31s/step - loss: 0.6366 - accuracy: 0.6694\n",
      "Epoch 19/24\n",
      "2/2 [==============================] - 102s 29s/step - loss: 0.6365 - accuracy: 0.6694\n",
      "Epoch 20/24\n",
      "2/2 [==============================] - 102s 31s/step - loss: 0.6367 - accuracy: 0.6694\n",
      "Epoch 21/24\n",
      "2/2 [==============================] - 99s 29s/step - loss: 0.6368 - accuracy: 0.6694\n",
      "Epoch 22/24\n",
      "2/2 [==============================] - 106s 28s/step - loss: 0.6361 - accuracy: 0.6694\n",
      "Epoch 23/24\n",
      "2/2 [==============================] - 105s 30s/step - loss: 0.6360 - accuracy: 0.6694\n",
      "Epoch 24/24\n",
      "2/2 [==============================] - 104s 30s/step - loss: 0.6361 - accuracy: 0.6694\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1dc3603a4a0>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a list 'data' containing tuples of (DataFrame, label)\n",
    "# where each DataFrame represents the time series data for a patient\n",
    "# and 'label' is the corresponding classification (1 or 0)\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "X = [df.values for df, _ in data]  # List of numpy arrays\n",
    "y = np.array([label for _, label in data])\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "max_length = max(len(x) for x in X)\n",
    "X_padded = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_length, padding='post', dtype='float32')\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(max_length, 24)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_padded, y, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T06:10:21.353030Z",
     "start_time": "2024-03-25T04:59:02.482220Z"
    }
   },
   "id": "206ade4d5c131b18",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
